"""
å¤šæ¨¡å‹æ”¯æŒç¤ºä¾‹
å±•ç¤ºå¦‚ä½•åœ¨ LangChain ä¸­ä½¿ç”¨ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹
"""
import os
from dotenv import load_dotenv
from langchain.agents import create_agent

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯"""
    weather_data = {
        "åŒ—äº¬": "å¤šäº‘ï¼Œæ¸©åº¦ 15Â°C",
        "ä¸Šæµ·": "æ™´æœ—ï¼Œæ¸©åº¦ 20Â°C",
        "æ·±åœ³": "é˜´å¤©ï¼Œæ¸©åº¦ 25Â°C",
        "æ—§é‡‘å±±": "æ™´æœ—ï¼Œæ¸©åº¦ 18Â°C",
    }
    return weather_data.get(city, f"{city} å¤©æ°”æ€»æ˜¯æ™´æœ—ï¼æ¸©åº¦é€‚å®œã€‚")


def calculate(expression: str) -> str:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
    try:
        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"


def get_model_config():
    """æ ¹æ®ç¯å¢ƒå˜é‡è·å–æ¨¡å‹é…ç½®"""
    provider = os.getenv("MODEL_PROVIDER", "anthropic").lower()
    
    model_configs = {
        "anthropic": {
            "model": "anthropic:claude-sonnet-4-5",
            "name": "Anthropic Claude Sonnet 4.5",
            "env_key": "ANTHROPIC_API_KEY",
        },
        "openai": {
            "model": "openai:gpt-4o",
            "name": "OpenAI GPT-4o",
            "env_key": "OPENAI_API_KEY",
        },
        "google": {
            "model": "google:gemini-2.0-flash-exp",
            "name": "Google Gemini 2.0 Flash",
            "env_key": "GOOGLE_API_KEY",
        },
        "deepseek": {
            "model": "openai:deepseek-chat",
            "name": "DeepSeek V3 (æ¨è)",
            "env_key": "DEEPSEEK_API_KEY",
            "base_url": "https://api.deepseek.com",
        },
        "dashscope": {
            "model": "dashscope:qwen-max",
            "name": "é˜¿é‡Œäº‘é€šä¹‰åƒé—® Max",
            "env_key": "DASHSCOPE_API_KEY",
        },
        "zhipuai": {
            "model": "zhipuai:glm-4",
            "name": "æ™ºè°± ChatGLM-4",
            "env_key": "ZHIPUAI_API_KEY",
        },
    }
    
    return model_configs.get(provider, model_configs["anthropic"])


def create_agent_with_model(model_name: str = None, base_url: str = None):
    """åˆ›å»ºä½¿ç”¨æŒ‡å®šæ¨¡å‹çš„ä»£ç†"""
    
    if model_name:
        config = {"model": model_name, "name": model_name, "base_url": base_url}
    else:
        config = get_model_config()
    
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {config['name']}")
    print(f"ğŸ“‹ æ¨¡å‹æ ‡è¯†: {config['model']}")
    
    # å¤„ç† DeepSeek çš„ç‰¹æ®Šé…ç½®
    model_str = config["model"]
    if config.get("base_url"):
        print(f"ğŸŒ API åœ°å€: {config['base_url']}")
        # DeepSeek éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡
        if "deepseek" in config["name"].lower():
            os.environ["OPENAI_API_KEY"] = os.getenv("DEEPSEEK_API_KEY", "")
            os.environ["OPENAI_API_BASE"] = config["base_url"]
    
    # åˆ›å»ºä»£ç†
    agent = create_agent(
        model=model_str,
        tools=[get_weather, calculate],
        system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„æ™ºèƒ½åŠ©æ‰‹ã€‚ä½ å¯ä»¥ï¼š
        1. æŸ¥è¯¢å¤©æ°”ä¿¡æ¯
        2. è¿›è¡Œæ•°å­¦è®¡ç®—
        
        è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å›ç­”ã€‚å›ç­”è¦ç®€æ´ã€å‡†ç¡®ã€å‹å¥½ã€‚""",
    )
    
    return agent


def compare_models():
    """å¯¹æ¯”ä¸åŒæ¨¡å‹çš„å“åº”"""
    print("=" * 70)
    print("LangChain å¤šæ¨¡å‹å¯¹æ¯”ç¤ºä¾‹")
    print("=" * 70)
    
    # å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
    available_models = []
    
    if os.getenv("DEEPSEEK_API_KEY"):
        available_models.append(("openai:deepseek-chat", "DeepSeek V3", "https://api.deepseek.com"))
    if os.getenv("ANTHROPIC_API_KEY"):
        available_models.append(("anthropic:claude-sonnet-4-5", "Anthropic Claude", None))
    if os.getenv("OPENAI_API_KEY"):
        available_models.append(("openai:gpt-4o", "OpenAI GPT-4o", None))
    if os.getenv("GOOGLE_API_KEY"):
        available_models.append(("google:gemini-2.0-flash-exp", "Google Gemini", None))
    
    if not available_models:
        print("\nâŒ é”™è¯¯: è¯·è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹çš„ API Key")
        print("\nè¯·ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ä»¥ä¸‹ä»»ä¸€ API Key:")
        print("  - DEEPSEEK_API_KEY (æ¨è)")
        print("  - ANTHROPIC_API_KEY")
        print("  - OPENAI_API_KEY")
        print("  - GOOGLE_API_KEY")
        return
    
    print(f"\nâœ… æ£€æµ‹åˆ° {len(available_models)} ä¸ªå¯ç”¨æ¨¡å‹\n")
    
    # æµ‹è¯•é—®é¢˜
    query = "ä¸Šæµ·çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
    
    # å¯¹æ¯”æ¯ä¸ªæ¨¡å‹çš„å“åº”
    for model_info in available_models:
        model_id = model_info[0]
        model_name = model_info[1]
        base_url = model_info[2] if len(model_info) > 2 else None
        
        print("\n" + "=" * 70)
        print(f"ğŸ“ æ¨¡å‹: {model_name}")
        print("-" * 70)
        print(f"ç”¨æˆ·: {query}")
        print("-" * 70)
        
        try:
            # ç‰¹æ®Šå¤„ç† DeepSeek
            if "deepseek" in model_name.lower() and base_url:
                os.environ["OPENAI_API_KEY"] = os.getenv("DEEPSEEK_API_KEY", "")
                os.environ["OPENAI_API_BASE"] = base_url
            
            agent = create_agent_with_model(model_id, base_url)
            response = agent.invoke(
                {"messages": [{"role": "user", "content": query}]}
            )
            print(f"åŠ©æ‰‹: {response}")
        except Exception as e:
            print(f"âŒ é”™è¯¯: {str(e)}")


def single_model_demo():
    """ä½¿ç”¨é…ç½®çš„å•ä¸ªæ¨¡å‹è¿›è¡Œæ¼”ç¤º"""
    print("=" * 70)
    print("LangChain æ™ºèƒ½ä»£ç† - å¤šæ¨¡å‹æ”¯æŒ")
    print("=" * 70)
    
    try:
        # åˆ›å»ºä»£ç†
        agent = create_agent_with_model()
        
        print("\n" + "=" * 70)
        
        # æµ‹è¯•é—®é¢˜
        test_queries = [
            "åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
            "å¸®æˆ‘è®¡ç®— 256 * 384",
        ]
        
        for query in test_queries:
            print(f"\nç”¨æˆ·: {query}")
            print("-" * 70)
            
            try:
                response = agent.invoke(
                    {"messages": [{"role": "user", "content": query}]}
                )
                print(f"åŠ©æ‰‹: {response}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {str(e)}")
        
        print("\n" + "=" * 70)
        print("æ¼”ç¤ºç»“æŸï¼")
        print("=" * 70)
        
    except Exception as e:
        print(f"\nâŒ åˆå§‹åŒ–é”™è¯¯: {str(e)}")
        print("\nè¯·æ£€æŸ¥:")
        print("1. .env æ–‡ä»¶ä¸­å¯¹åº”çš„ API Key æ˜¯å¦æ­£ç¡®é…ç½®")
        print("2. MODEL_PROVIDER è®¾ç½®æ˜¯å¦æ­£ç¡®")


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--compare":
        # å¯¹æ¯”æ¨¡å¼
        compare_models()
    else:
        # å•æ¨¡å‹æ¼”ç¤ºæ¨¡å¼
        single_model_demo()
        print("\nğŸ’¡ æç¤º: ä½¿ç”¨ 'python multi_model_example.py --compare' å¯å¯¹æ¯”å¤šä¸ªæ¨¡å‹")


if __name__ == "__main__":
    main()
